{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#libs\n",
    "import pandas as pd\n",
    "\n",
    "#import data\n",
    "df = pd.read_csv('ecommerce-session-bigquery.csv')\n",
    "\n",
    "\n",
    "df = df.loc[pd.notnull(df['date'])]\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CASE STUDY 1\n",
    "\n",
    "CHATGPT\n",
    "\n",
    "Prompt :\n",
    "I have infomation about the total transaction revenue, date, product name and product category. Help me to make python code for identifying top products based on the total transaction revenue per day.  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW \n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Sample data (replace this with your actual data)\n",
    "data = {\n",
    "    \"Date\": [\"2023-12-01\", \"2023-12-01\", \"2023-12-02\", \"2023-12-02\", \"2023-12-02\"],\n",
    "    \"Product Name\": [\"Product A\", \"Product B\", \"Product A\", \"Product C\", \"Product B\"],\n",
    "    \"Product Category\": [\"Category 1\", \"Category 2\", \"Category 1\", \"Category 3\", \"Category 2\"],\n",
    "    \"Transaction Revenue\": [100, 200, 150, 300, 250],\n",
    "}\n",
    "\n",
    "# Convert data to a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Ensure the 'Date' column is in datetime format\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "# Group by Date and Product Name, summing up the Transaction Revenue\n",
    "daily_revenue = df.groupby(['Date', 'Product Name'], as_index=False).agg({\n",
    "    'Transaction Revenue': 'sum'\n",
    "})\n",
    "\n",
    "# Sort the grouped data by Date and Transaction Revenue in descending order\n",
    "daily_revenue = daily_revenue.sort_values(by=['Date', 'Transaction Revenue'], ascending=[True, False])\n",
    "\n",
    "# Find the top product for each day\n",
    "top_product_per_day = daily_revenue.loc[daily_revenue.groupby('Date')['Transaction Revenue'].idxmax()]\n",
    "\n",
    "print(\"Top product per day:\")\n",
    "print(top_product_per_day)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample Data Adjustment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#REPLACED WITH THE DATA\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "#import data\n",
    "df = pd.read_csv('ecommerce-session-bigquery.csv')\n",
    "\n",
    "\n",
    "df = df.loc[pd.notnull(df['date'])]\n",
    "\n",
    "# Ensure the 'Date' column is in datetime format\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "# Group by Date and Product Name, summing up the Transaction Revenue\n",
    "daily_revenue = df.groupby(['date', 'v2ProductName', 'v2ProductCategory'], as_index=False).agg({\n",
    "    'totalTransactionRevenue': 'sum'\n",
    "})\n",
    "\n",
    "# Sort the grouped data by Date and Transaction Revenue in descending order\n",
    "daily_revenue = daily_revenue.sort_values(by=['date', 'totalTransactionRevenue'], ascending=[True, False])\n",
    "\n",
    "# Find the top product(s) for each day\n",
    "top_products_per_day = daily_revenue.loc[daily_revenue.groupby('date')['totalTransactionRevenue'].idxmax()]\n",
    "\n",
    "print(\"Top products per day:\")\n",
    "print(top_products_per_day)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPROVED SOLUTIONS\n",
    "\n",
    "The solutions by CHATGPT have invalid converting results and caused the group-by function not working properly. I enhanced the step to convert the data from YYYYMMDD to YYYY-MM-DD format to create a better result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#REPLACED WITH THE DATA\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "#import data\n",
    "df = pd.read_csv('ecommerce-session-bigquery.csv')\n",
    "\n",
    "\n",
    "df = df.loc[pd.notnull(df['date'])]\n",
    "\n",
    "# Ensure the 'Date' column is in datetime format\n",
    "df['date'] = pd.to_datetime(df['date'].astype(str), format='%Y%m%d')\n",
    "\n",
    "# Group by Date and Product Name, summing up the Transaction Revenue\n",
    "daily_revenue = df.groupby(['date', 'v2ProductName', 'v2ProductCategory'], as_index=False).agg({\n",
    "    'totalTransactionRevenue': 'sum'\n",
    "})\n",
    "\n",
    "# Sort the grouped data by Date and Transaction Revenue in descending order\n",
    "daily_revenue = daily_revenue.sort_values(by=['date', 'totalTransactionRevenue'], ascending=[True, False])\n",
    "\n",
    "# Find the top product(s) for each day\n",
    "top_products_per_day = daily_revenue.loc[daily_revenue.groupby('date')['totalTransactionRevenue'].idxmax()]\n",
    "\n",
    "print(\"Top products per day:\")\n",
    "display(top_products_per_day)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CASE STUDY 2\n",
    "\n",
    "CHATGPT\n",
    "\n",
    "Prompt :\n",
    "I have infomation about the total transaction revenue, date, product name and product category. Help me to make python code for detecting any anomalies, such as a sharp decrease or increase in the number of transactions for a specific product. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import zscore\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Example DataFrame: Replace this with your actual data\n",
    "data = {\n",
    "    'date': ['2024-11-01', '2024-11-01', '2024-11-02', '2024-11-02',\n",
    "             '2024-11-03', '2024-11-03'],\n",
    "    'product_name': ['Product A', 'Product B', 'Product A', 'Product B',\n",
    "                     'Product A', 'Product B'],\n",
    "    'product_category': ['Category 1', 'Category 1', 'Category 1', 'Category 1',\n",
    "                         'Category 1', 'Category 1'],\n",
    "    'transaction_revenue': [100, 200, 300, 150, 50, 250]\n",
    "}\n",
    "\n",
    "# Convert the data into a pandas DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "# Group by date and product to get transaction counts (or sums of revenue)\n",
    "transaction_summary = df.groupby(['date', 'product_name'])['transaction_revenue'].sum().reset_index()\n",
    "\n",
    "# Function to detect anomalies for a specific product\n",
    "def detect_anomalies(product_name, transaction_summary, threshold=1):\n",
    "    product_data = transaction_summary[transaction_summary['product_name'] == product_name]\n",
    "    product_data['zscore'] = zscore(product_data['transaction_revenue'])\n",
    "\n",
    "    # Identify anomalies based on Z-score\n",
    "    anomalies = product_data[np.abs(product_data['zscore']) > threshold]\n",
    "\n",
    "    # Plot for visualization\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(product_data['date'], product_data['transaction_revenue'], label='Transaction Revenue')\n",
    "    plt.scatter(anomalies['date'], anomalies['transaction_revenue'], color='red', label='Anomalies')\n",
    "    plt.title(f'Transaction Trend for {product_name}')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Transaction Revenue')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    return anomalies\n",
    "\n",
    "# Example usage: Detect anomalies for \"Product A\"\n",
    "product_name = 'Product A'\n",
    "anomalies = detect_anomalies(product_name, transaction_summary)\n",
    "\n",
    "# Output the anomalies\n",
    "print(f\"Anomalies detected for {product_name}:\")\n",
    "print(anomalies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample Data Adjustment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import zscore\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import data\n",
    "df = pd.read_csv('ecommerce-session-bigquery.csv')\n",
    "\n",
    "# Filter rows with non-null dates\n",
    "df = df.loc[pd.notnull(df['date'])]\n",
    "\n",
    "# Ensure the 'date' column is in datetime format\n",
    "df['date'] = pd.to_datetime(df['date'].astype(str), format='%Y%m%d')\n",
    "\n",
    "# Group by date and product to get transaction counts (or sums of revenue)\n",
    "transaction_summary = df.groupby(['date', 'v2ProductName'])['totalTransactionRevenue'].sum().reset_index()\n",
    "\n",
    "# Function to detect anomalies for a specific product\n",
    "def detect_anomalies(v2ProductName, transaction_summary, threshold=2):\n",
    "    product_data = transaction_summary[transaction_summary['v2ProductName'] == v2ProductName].copy()\n",
    "    product_data['zscore'] = zscore(product_data['totalTransactionRevenue'])\n",
    "    \n",
    "    # Identify anomalies based on Z-score\n",
    "    anomalies = product_data[np.abs(product_data['zscore']) > threshold]\n",
    "    \n",
    "    # Plot for visualization\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(product_data['date'], product_data['totalTransactionRevenue'], label='Transaction Revenue', marker='o')\n",
    "    plt.scatter(anomalies['date'], anomalies['totalTransactionRevenue'], color='red', label='Anomalies')\n",
    "    plt.title(f'Transaction Trend for {v2ProductName}')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Transaction Revenue')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    \n",
    "    return anomalies\n",
    "\n",
    "# Example usage: Detect anomalies for \"Chevron Shopper\"\n",
    "v2ProductName = 'Chevron Shopper'\n",
    "anomalies = detect_anomalies(v2ProductName, transaction_summary)\n",
    "\n",
    "# Output the anomalies\n",
    "print(f\"Anomalies detected for {v2ProductName}:\")\n",
    "print(anomalies)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the CHATGPT results using the Z-score method with threshold = 2, no anomaly was found. I tried reducing the threshold to 1.5, 2 rows were read as anomalies. With a smaller threshold, it can detect subtle anomalies. However, the model becomes more sensitive to smaller fluctuations in the data which may be a natural variation in daily transactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import zscore\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import data\n",
    "df = pd.read_csv('ecommerce-session-bigquery.csv')\n",
    "\n",
    "# Filter rows with non-null dates\n",
    "df = df.loc[pd.notnull(df['date'])]\n",
    "\n",
    "# Ensure the 'date' column is in datetime format\n",
    "df['date'] = pd.to_datetime(df['date'].astype(str), format='%Y%m%d')\n",
    "\n",
    "# Group by date and product to get transaction counts (or sums of revenue)\n",
    "transaction_summary = df.groupby(['date', 'v2ProductName'])['totalTransactionRevenue'].sum().reset_index()\n",
    "\n",
    "# Function to detect anomalies for a specific product\n",
    "def detect_anomalies(v2ProductName, transaction_summary, threshold=1.5):\n",
    "    product_data = transaction_summary[transaction_summary['v2ProductName'] == v2ProductName].copy()\n",
    "    product_data['zscore'] = zscore(product_data['totalTransactionRevenue'])\n",
    "    \n",
    "    # Identify anomalies based on Z-score\n",
    "    anomalies = product_data[np.abs(product_data['zscore']) > threshold]\n",
    "    \n",
    "    # Plot for visualization\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(product_data['date'], product_data['totalTransactionRevenue'], label='Transaction Revenue', marker='o')\n",
    "    plt.scatter(anomalies['date'], anomalies['totalTransactionRevenue'], color='red', label='Anomalies')\n",
    "    plt.title(f'Transaction Trend for {v2ProductName}')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Transaction Revenue')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    \n",
    "    return anomalies\n",
    "\n",
    "# Example usage: Detect anomalies for \"Chevron Shopper\"\n",
    "v2ProductName = 'Chevron Shopper'\n",
    "anomalies = detect_anomalies(v2ProductName, transaction_summary)\n",
    "\n",
    "# Output the anomalies\n",
    "print(f\"Anomalies detected for {v2ProductName}:\")\n",
    "print(anomalies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
